{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# RILA EDA: Feature Selection with AIC - REFACTORED\n",
    "\n",
    "**Refactored:** 2026-01-28  \n",
    "**Original:** notebooks/rila/04_RILA_feature_selection.ipynb  \n",
    "\n",
    "**Changes:**\n",
    "- Migrated data loading from helpers.* to src.* imports\n",
    "- Added canonical sys.path auto-detection\n",
    "- Preserved AIC selection logic inline (no direct src equivalent)\n",
    "- Kept position lag features inline (experiment-specific)\n",
    "- Kept BaggingRegressor/Ridge ensemble inline (EDA-appropriate)\n",
    "- Improved cell structure and documentation\n",
    "\n",
    "**Purpose:** Feature selection using AIC-based exhaustive search and model comparison with bagging ensemble validation.\n",
    "\n",
    "**Dependencies:** 03_EDA_RILA_feature_engineering.ipynb (requires engineered features)\n",
    "\n",
    "**Note:** AIC selection logic kept inline per EDA principles - no clear src equivalent exists. This allows for exploratory flexibility in feature combination search.\n",
    "\n",
    "## Notebook Outline\n",
    "1. Setup and data loading\n",
    "2. Position lag feature engineering\n",
    "3. AIC-based feature selection\n",
    "4. Model validation with bagging ensemble\n",
    "5. Results visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# =============================================================================\n",
    "# STANDARD SETUP CELL - Clean Dependency Pattern\n",
    "# =============================================================================\n",
    "\n",
    "# Standard library imports\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import product\n",
    "from typing import Union\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, RepeatedKFold, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    mean_absolute_percentage_error,\n",
    ")\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Suppress warnings for clean output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Canonical sys.path setup (auto-detect project root)\n",
    "if os.path.basename(os.getcwd()) == \"rila\":\n",
    "    # Running from notebooks/rila directory\n",
    "    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "elif os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    # Running from notebooks directory\n",
    "    project_root = os.path.dirname(os.getcwd())\n",
    "else:\n",
    "    # Running from project root\n",
    "    project_root = os.getcwd()\n",
    "\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Refactored imports (src.* pattern)\n",
    "from src.data import extraction as ext\n",
    "from src.data.dvc_manager import load_dataset\n",
    "\n",
    "# Matplotlib inline mode\n",
    "%matplotlib inline\n",
    "\n",
    "# Visualization theme\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"deep\")\n",
    "\n",
    "print(\"✓ Dependencies loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# AWS configuration\n",
    "aws_config = {\n",
    "    \"xid\": \"x259830\",\n",
    "    \"role_arn\": \"arn:aws:iam::159058241883:role/isg-usbie-annuity-CA-s3-sharing\",\n",
    "    \"sts_endpoint_url\": \"https://sts.us-east-1.amazonaws.com\",\n",
    "    \"source_bucket_name\": \"pruvpcaws031-east-isg-ie-lake\",\n",
    "    \"output_bucket_name\": \"cdo-annuity-364524684987-bucket\",\n",
    "    \"output_base_path\": \"ANN_Price_Elasticity_Data_Science\",\n",
    "}\n",
    "\n",
    "# Date parameters\n",
    "current_time = datetime.now()\n",
    "current_date = current_time.strftime(\"%Y-%m-%d\")\n",
    "date_path = f\"year={current_time.year}/month={current_time.month:02}/day={current_time.day:02}\"\n",
    "current_date_of_mature_data = (current_time - timedelta(days=0)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Version\n",
    "version = \"v2_0\"\n",
    "\n",
    "print(f\"✓ Configuration loaded\")\n",
    "print(f\"  Version: {version}\")\n",
    "print(f\"  Current date: {current_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data-header",
   "metadata": {},
   "source": [
    "## 1. Load Engineered Features\n",
    "\n",
    "Load the final dataset with all engineered features from notebook 03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD DATA - Using DVC or S3 direct\n",
    "# =============================================================================\n",
    "\n",
    "# Try DVC first, fallback to S3\n",
    "try:\n",
    "    df_RILA = load_dataset(\"RILA_final_data_set\", version=version)\n",
    "    print(\"✓ Data loaded from DVC\")\n",
    "except Exception as e:\n",
    "    print(f\"DVC load failed: {e}\")\n",
    "    print(\"Attempting S3 direct load...\")\n",
    "    \n",
    "    # AWS Connection setup\n",
    "    sts_client = ext.setup_aws_sts_client_with_validation(aws_config)\n",
    "    assumed_role = ext.assume_iam_role_with_validation(sts_client, aws_config)\n",
    "    s3_resource, bucket = ext.setup_s3_resource_with_validation(\n",
    "        assumed_role[\"Credentials\"], aws_config[\"output_bucket_name\"]\n",
    "    )\n",
    "    \n",
    "    # S3 path\n",
    "    file_path = f\"RILA_{version}/features/{date_path}/\"\n",
    "    file_name = \"RILA_final_data_set\"\n",
    "    \n",
    "    # Load from S3\n",
    "    df_RILA = ext.download_s3_parquet_with_optional_date_suffix(\n",
    "        s3_resource, bucket, f\"{file_path}{file_name}\"\n",
    "    )\n",
    "    print(\"✓ Data loaded from S3\")\n",
    "\n",
    "print(f\"  Shape: {df_RILA.shape}\")\n",
    "print(f\"  Date range: {df_RILA['date'].min()} to {df_RILA['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filter-header",
   "metadata": {},
   "source": [
    "## 2. Position Lag Features\n",
    "\n",
    "Create position lag features with exponential weighting. These capture the relative position of Prudential rates vs competitor rates over time.\n",
    "\n",
    "**Note:** Kept inline per EDA principles - experiment-specific transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-engineering-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA FILTERING AND POSITION LAG FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "# Filter to non-zero sales\n",
    "df_RILA = df_RILA[df_RILA[\"sales\"] != 0]\n",
    "\n",
    "# Exponential weighting (more weight to recent observations)\n",
    "df_RILA[\"weight\"] = [0.98 ** (len(df_RILA) - k) for k in range(len(df_RILA))]\n",
    "\n",
    "# Position lag features: capture when Prudential rate is below competitor\n",
    "for k in range(15):\n",
    "    # pos_lag_k = max(0, C_lag - P_lag) captures when competitor is higher\n",
    "    df_RILA[f\"pos_lag_{k}\"] = np.abs(\n",
    "        df_RILA[f\"C_lag_{k+2}\"] - df_RILA[f\"P_lag_{k}\"]\n",
    "    ) - (df_RILA[f\"C_lag_{k+2}\"] - df_RILA[f\"P_lag_{k}\"])\n",
    "    \n",
    "    # Scaled version: interaction with Prudential rate level\n",
    "    df_RILA[f\"pos_lag_scale_{k}\"] = (\n",
    "        df_RILA[f\"pos_lag_{k}\"] * df_RILA[f\"P_lag_{k}\"]\n",
    "    )\n",
    "    \n",
    "    # Squared version: non-linear effect\n",
    "    df_RILA[f\"pos_lag_sq_{k}\"] = df_RILA[f\"pos_lag_{k}\"] ** 2\n",
    "\n",
    "# Time filtering\n",
    "mask_time = df_RILA[\"date\"] > pd.to_datetime(\"2022-05-01\")\n",
    "df_RILA = df_RILA[mask_time]\n",
    "df_RILA = df_RILA[df_RILA[\"date\"] < current_date_of_mature_data].dropna(\n",
    "    subset=\"C_lag_13\"\n",
    ")\n",
    "\n",
    "# Remove holidays\n",
    "df_RILA = df_RILA[df_RILA[\"holiday\"] == 0]\n",
    "\n",
    "print(f\"✓ Position lag features created\")\n",
    "print(f\"  Filtered shape: {df_RILA.shape}\")\n",
    "print(f\"  Observations: {len(df_RILA)}\")\n",
    "df_RILA[[\"date\", \"sales\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aic-header",
   "metadata": {},
   "source": [
    "## 3. AIC-Based Feature Selection\n",
    "\n",
    "**Note:** AIC selection logic kept inline - no direct equivalent in src.features.selection for this exhaustive combinatorial search approach.\n",
    "\n",
    "This cell performs exhaustive feature search using AIC (Akaike Information Criterion) to balance model fit and complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aic-inline-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AIC SELECTION FUNCTIONS - Inline (no src equivalent)\n",
    "# =============================================================================\n",
    "\n",
    "def best_subset_ols_strict(\n",
    "    df,\n",
    "    new_features,\n",
    "    old_features,\n",
    "    target_variable=\"sales_forward_0\",\n",
    "    target_weight=None,\n",
    "    lim_num=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    AIC-based exhaustive feature selection.\n",
    "    \n",
    "    Searches through all combinations of new_features to add to old_features,\n",
    "    selecting the combination with the lowest AIC.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with features and target\n",
    "        new_features: List of candidate feature combinations (strings like \"P_lag_0+C_lag_2\")\n",
    "        old_features: List of features to always include\n",
    "        target_variable: Target column name\n",
    "        target_weight: Optional weight column\n",
    "        lim_num: Number of features to add from new_features\n",
    "    \n",
    "    Returns:\n",
    "        AIC_min_list: List of minimum AIC values\n",
    "        N_obs_validation_list: List of observation counts\n",
    "        old_features_iterated: Updated feature list\n",
    "        df_results_all: DataFrame with all tried combinations and AICs\n",
    "    \"\"\"\n",
    "    AIC_min_list = []\n",
    "    N_obs_validation_list = []\n",
    "    old_features_iterated = old_features.copy()\n",
    "    df_results_all = pd.DataFrame(columns=[\"feature_name\", \"AIC\", \"N_obs\"])\n",
    "    \n",
    "    for iteration in range(lim_num):\n",
    "        AIC_min = np.inf\n",
    "        best_feature = None\n",
    "        \n",
    "        # Try each new feature\n",
    "        for idx, feature_combo in enumerate(new_features):\n",
    "            if idx % 100 == 0:\n",
    "                print(f\"{idx}/{len(new_features)}\")\n",
    "            \n",
    "            # Parse feature combination (e.g., \"P_lag_0+C_lag_2\")\n",
    "            features_to_test = old_features_iterated + feature_combo.split(\"+\")\n",
    "            \n",
    "            # Check all features exist\n",
    "            if not all(f in df.columns for f in features_to_test):\n",
    "                continue\n",
    "            \n",
    "            # Fit OLS model\n",
    "            try:\n",
    "                X = df[features_to_test].copy()\n",
    "                X = sm.add_constant(X)\n",
    "                y = df[target_variable]\n",
    "                \n",
    "                if target_weight:\n",
    "                    weights = df[target_weight]\n",
    "                    model = sm.OLS(y, X, weights=weights).fit()\n",
    "                else:\n",
    "                    model = sm.OLS(y, X).fit()\n",
    "                \n",
    "                aic = model.aic\n",
    "                n_obs = model.nobs\n",
    "                \n",
    "                # Store result\n",
    "                df_results_all = pd.concat([\n",
    "                    df_results_all,\n",
    "                    pd.DataFrame({\"feature_name\": [feature_combo], \"AIC\": [aic], \"N_obs\": [n_obs]})\n",
    "                ], ignore_index=True)\n",
    "                \n",
    "                # Track best\n",
    "                if aic < AIC_min:\n",
    "                    AIC_min = aic\n",
    "                    best_feature = feature_combo\n",
    "                    N_obs_validation = n_obs\n",
    "            \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        # Add best feature to old_features\n",
    "        if best_feature:\n",
    "            AIC_min_list.append(AIC_min)\n",
    "            N_obs_validation_list.append(N_obs_validation)\n",
    "            old_features_iterated.extend(best_feature.split(\"+\"))\n",
    "            \n",
    "            # Refit with best features and display\n",
    "            X = df[old_features_iterated].copy()\n",
    "            X = sm.add_constant(X)\n",
    "            y = df[target_variable]\n",
    "            \n",
    "            if target_weight:\n",
    "                weights = df[target_weight]\n",
    "                model = sm.OLS(y, X, weights=weights).fit()\n",
    "            else:\n",
    "                model = sm.OLS(y, X).fit()\n",
    "            \n",
    "            print(model.summary())\n",
    "    \n",
    "    return AIC_min_list, N_obs_validation_list, old_features_iterated, df_results_all\n",
    "\n",
    "print(\"✓ AIC selection functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aic-selection-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AIC FEATURE SELECTION - Exhaustive Search\n",
    "# =============================================================================\n",
    "\n",
    "# Starting features (empty for fresh search)\n",
    "old_features = []\n",
    "\n",
    "# Generate candidate feature combinations\n",
    "L = 2  # Lag offset for competitor rates\n",
    "new_features = []\n",
    "\n",
    "# Combinations with C_diff (rate changes)\n",
    "for j in range(4):\n",
    "    new_features += [\n",
    "        f\"P_lag_{k}+C_lag_{k+L}+C_diff_lag_{k+L+j+1}+sales_by_contract_date_lag_{k+L+1}\"\n",
    "        for k in range(0, 6, 1)\n",
    "    ]\n",
    "\n",
    "# Combinations with sales lags\n",
    "for j in range(4):\n",
    "    new_features += [\n",
    "        f\"P_lag_{k}+C_lag_{k+L}+sales_by_contract_date_lag_{k+L+j+1}\"\n",
    "        for k in range(0, 6, 1)\n",
    "    ]\n",
    "\n",
    "# Combinations with rate changes only\n",
    "for j in range(4):\n",
    "    new_features += [\n",
    "        f\"P_lag_{k}+C_lag_{k+L}+C_diff_lag_{k+L+j+1}\" for k in range(0, 6, 1)\n",
    "    ]\n",
    "\n",
    "# Base combinations (just rates)\n",
    "for j in range(4):\n",
    "    new_features += [f\"P_lag_{k}+C_lag_{k+L}\" for k in range(0, 6, 1)]\n",
    "\n",
    "print(f\"Testing {len(new_features)} feature combinations\")\n",
    "\n",
    "# Run AIC selection\n",
    "AIC_min_list, N_obs_validation_list, old_features_iterated, df_results_all = (\n",
    "    best_subset_ols_strict(\n",
    "        df_RILA,\n",
    "        new_features,\n",
    "        old_features,\n",
    "        target_variable=\"sales_forward_0\",\n",
    "        lim_num=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ AIC selection complete\")\n",
    "print(f\"  Minimum AIC: {AIC_min_list}\")\n",
    "print(f\"  Selected features: {old_features_iterated}\")\n",
    "\n",
    "# Display top AIC results\n",
    "df_AIC_list = (\n",
    "    df_results_all[[\"feature_name\", \"AIC\", \"N_obs\"]]\n",
    "    .sort_values(by=[\"AIC\"], ascending=True)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(\"\\nTop 10 feature combinations by AIC:\")\n",
    "print(df_AIC_list.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bagging-header",
   "metadata": {},
   "source": [
    "## 4. Model Validation with Bagging Ensemble\n",
    "\n",
    "Validate selected features using BaggingRegressor with Ridge estimators.\n",
    "\n",
    "**Note:** Kept inline per EDA principles - experiment-specific ensemble validation approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bagging-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BAGGING ENSEMBLE VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "df = df_RILA.copy()\n",
    "df[\"weight\"] = [0.99 ** (len(df) - k) for k in range(len(df))]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Target variables\n",
    "target_variable = \"sales_forward_0\"\n",
    "target_variable_alt = \"sales_by_contract_date_lag_0\"\n",
    "\n",
    "# Selected features from AIC\n",
    "features = old_features_iterated\n",
    "\n",
    "# Spread calculation (for visualization)\n",
    "df[\"Spread\"] = df[\"P_lag_4\"] - df[\"C_lag_6\"]\n",
    "\n",
    "# Prepare data\n",
    "X = df[features]\n",
    "y = df[target_variable_alt]\n",
    "y_test_orig = df[target_variable_alt]\n",
    "\n",
    "# Bagging setup\n",
    "N_iter = 100\n",
    "scores_MAPE = np.zeros(N_iter)\n",
    "scores_MAPE_orig = np.zeros(N_iter)\n",
    "scores_AE = np.zeros(N_iter)\n",
    "scores_r2 = np.zeros(N_iter)\n",
    "scores_r2_orig = np.zeros(N_iter)\n",
    "\n",
    "# Results storage\n",
    "df_results = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"date\",\n",
    "        \"spread\",\n",
    "        \"y_predict\",\n",
    "        \"y_predict_orig\",\n",
    "        \"y\",\n",
    "        \"y_orig\",\n",
    "        \"run\",\n",
    "        \"quarter\",\n",
    "        \"residual\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit bagging model\n",
    "print(\"Fitting bagging ensemble...\")\n",
    "model = BaggingRegressor(estimator=Ridge(), n_estimators=N_iter, random_state=42)\n",
    "bagged_model = model.fit(df[features], df[target_variable])\n",
    "\n",
    "# Evaluate each estimator\n",
    "for k, lr_model in enumerate(bagged_model.estimators_):\n",
    "    y_predict = lr_model.predict(X)\n",
    "    y_predict_orig = y_predict\n",
    "    \n",
    "    # Store results\n",
    "    df_results_temp = pd.DataFrame({\n",
    "        \"spread\": df[\"Spread\"],\n",
    "        \"y_predict_orig\": y_predict_orig,\n",
    "        \"y_predict\": y_predict,\n",
    "        \"residual\": y - y_predict,\n",
    "        \"y\": y,\n",
    "        \"y_orig\": y_test_orig,\n",
    "        \"run\": k,\n",
    "        \"quarter\": df[\"quarter\"],\n",
    "        \"date\": df[\"date\"],\n",
    "    })\n",
    "    df_results = pd.concat([df_results, df_results_temp], ignore_index=True)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    sample_weights = y_test_orig / y_test_orig.sum()\n",
    "    scores_AE[k] = 100 * y_predict_orig.sum() / y_test_orig.sum()\n",
    "    scores_MAPE_orig[k] = 100 * mean_absolute_percentage_error(\n",
    "        y_test_orig, y_predict_orig, sample_weight=sample_weights\n",
    "    )\n",
    "    scores_MAPE[k] = 100 * mean_absolute_percentage_error(\n",
    "        y, y_predict, sample_weight=sample_weights\n",
    "    )\n",
    "    scores_r2[k] = r2_score(y, y_predict)\n",
    "    scores_r2_orig[k] = r2_score(y_test_orig, y_predict_orig)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n✓ Bagging validation complete\")\n",
    "print(f\"\\nR²:       {scores_r2_orig.mean():.3f}\")\n",
    "print(f\"std:      {scores_r2_orig.std():.3f}\\n\")\n",
    "print(f\"A/E:      {scores_AE.mean():.2f}%\")\n",
    "print(f\"std:      {scores_AE.std():.3f}\\n\")\n",
    "print(f\"MAPE:     {scores_MAPE_orig.mean():.2f}%\")\n",
    "print(f\"std:      {scores_MAPE_orig.std():.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## 5. Results Visualization\n",
    "\n",
    "Visualize model predictions vs actuals over time and vs cap rate spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RESULTS VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "figure, axes = plt.subplots(2, 1, sharex=False, sharey=False, figsize=(16, 10))\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"deep\")\n",
    "figure.suptitle(\"FlexGuard + PruAdvisors Feature Selection Results\", fontsize=16)\n",
    "\n",
    "# Time series plot\n",
    "axes[0].set_title(\"Predicted vs Actual Sales Over Time\")\n",
    "axes[0].set_xlabel(\"Date\")\n",
    "axes[0].set_ylabel(\"FlexGuard Sales ($)\")\n",
    "\n",
    "sns.lineplot(\n",
    "    df_results,\n",
    "    x=\"date\",\n",
    "    y=\"y_predict\",\n",
    "    ax=axes[0],\n",
    "    color=\"tab:blue\",\n",
    "    linewidth=5,\n",
    "    errorbar=(\"pi\", 95),\n",
    "    label=\"Predicted (95% PI)\",\n",
    ")\n",
    "sns.scatterplot(\n",
    "    data=df_results, x=\"date\", y=\"y\", ax=axes[0], color=\"k\", label=\"Actual\", alpha=0.6\n",
    ")\n",
    "axes[0].legend()\n",
    "\n",
    "# Spread plot\n",
    "axes[1].set_title(\"Sales vs Cap Rate Spread\")\n",
    "axes[1].set_xlabel(\"Cap Rate Distance to Mean Rate (bps)\")\n",
    "axes[1].set_ylabel(\"FlexGuard Sales ($)\")\n",
    "\n",
    "sns.lineplot(\n",
    "    df_results,\n",
    "    x=\"spread\",\n",
    "    y=\"y_predict\",\n",
    "    ax=axes[1],\n",
    "    color=\"tab:blue\",\n",
    "    linewidth=5,\n",
    "    errorbar=(\"pi\", 95),\n",
    "    label=\"Predicted (95% PI)\",\n",
    ")\n",
    "sns.scatterplot(\n",
    "    data=df_results, x=\"spread\", y=\"y\", ax=axes[1], color=\"k\", label=\"Actual\", alpha=0.6\n",
    ")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completion-cell",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## EDA Complete\n",
    "\n",
    "**Selected Features:** See `old_features_iterated` above\n",
    "\n",
    "**Model Performance:**\n",
    "- R²: See output above\n",
    "- MAPE: See output above\n",
    "- A/E: See output above\n",
    "\n",
    "**Next Steps:** \n",
    "- Proceed to 05_RILA_Time_Forward_Cross_Validation.ipynb for walk-forward validation\n",
    "- Use selected features in time series forecasting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
